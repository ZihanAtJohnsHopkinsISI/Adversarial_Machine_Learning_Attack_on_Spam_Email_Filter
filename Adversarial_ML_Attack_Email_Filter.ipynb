{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "HBdiD49e5Q7L"
      },
      "source": [
        "# **Adversarial Attacks Against Machine Learning Based Spam Filters**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "NPJYb7EA5a24"
      },
      "source": [
        "40 Points\n",
        "\n",
        "Author: Zihan Qu"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "eSubQvScyKdQ"
      },
      "source": [
        "## **Introduction**\n",
        "Machine learning-based spam detection models learn from a set of labeled training data and detect spam emails using this trained model. In this assignment, we study a class of vulnerabilities of such detection models, where the attack can manipulate the numerical features used in such a model ( e.g., TF-IDF vectors representing emails to a SVM classifier) to misclassify them during the detection phase. However, very often feature extraction methods make it difficult to translate a change made to the features to that in the textual email space. This lab uses a new attack method of making guided changes to the text in emails by taking advantage of purposely generated adversarial TF-IDF vetor representing emails. We identify a set of \"magic words\", or malicious words, to be added to a spam email, which can cause desirable misclassifications by classifiers. This attack works in a similar way to the so-called \"good word attack\".\n",
        "\n",
        "For more information on this attack approach, you can refer to the following publications:\n",
        "\n",
        "(1) Q. Cheng, A. Xu, X. Li, and L. Ding, “Adversarial Email Generation against Spam Detection Models through Feature Perturbation,” The 2022 IEEE International Conference on Assured Autonomy (ICAA’22), Virtual Event, March 22-23, 2022. [Download](https://isi.jhu.edu/wp-content/uploads/2022/04/Adversarial_Attacks_Against_Machine_Learning_Based_SpamFilters__IEEE.pdf)\n",
        "\n",
        "(2) J. He, Q. Cheng, and X. Li, “Understanding the Impact of Bad Words \n",
        "on Email Management through Adversarial Machine Learning,” SIG-KM International Research Symposium 2021, Virtual Event, The University of North Texas, September 29, 2021. [Download](https://isi.jhu.edu/wp-content/uploads/2021/10/Bad-Words-He-Cheng-Li-Rev.pdf)\n",
        "\n",
        "(3) C. Wang, D. Zhang, S. Huang, X. Li, and L. Ding, “Crafting Adversarial Email Content against Machine Learning Based Spam Email Detection,” In Proceedings of the 2021 International Symposium on Advanced Security on Software and Systems (ASSS ’21) with AsiaCCS 2021, Virtual Event, Hong Kong, June 7, 2021. [Download](https://isi.jhu.edu/wp-content/uploads/2021/04/ASSS_Workshop_Paper.pdf\n",
        ") "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "X4yidKOj0XYS"
      },
      "source": [
        "# Please note: \n",
        "\n",
        "* There will be a warning about deprecated frame.append mathod. It will not prevent you from completing the tasks.\n",
        "\n",
        "* Some tasks may take a little long time, e.g., a few minutes. Please be patient. \n",
        "\n",
        "* Pay attention to the \"Saving messages.csv to messages (4).csv\" after you upload the messages.csv file. Make sure the uploaded file names matches when you load the data later."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Sv-y6Ac6FYWO"
      },
      "source": [
        "## **1. Loading Dataset**\n",
        "We will be using the Ling-Spam (as used in a previous assignment). The Ling-Spam dataset is a collection of 2,893 spam and non-spam messages curated from Linguist List. The messages in the dataset revolve around linguistic interests, such as job postings, research opportunities and software discussion.\n",
        "\n",
        "### Acknowledgements\n",
        "The dataset and its information come from the original authors of \"A Memory-Based Approach to Anti-Spam Filtering for Mailing Lists\". The dataset was made publicly available as a part of that paper. \\\\\n",
        "\n",
        "**Run the code block below:**\n",
        "\n",
        "The code below chooses the message.csv to upload. Wait until it shows 100% before you continue."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "TXkAvUlp4fRP",
        "outputId": "24982c2a-54a6-495f-e982-5d5ac784f237"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-de3002a4-b7b8-4cf1-8e0a-2b7d0f0aea56\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-de3002a4-b7b8-4cf1-8e0a-2b7d0f0aea56\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving messages.csv to messages.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "1re2gZWrle_P"
      },
      "source": [
        "**Run the code block below:**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "FAHEUxXQcEqx"
      },
      "source": [
        "### Definition of each variables\n",
        "x_train: Training data features\n",
        "\n",
        "x_val  : Validation data features (This is used to find the magic words)\n",
        "\n",
        "x_test : Testing data features\n",
        "\n",
        "\\\\\n",
        "\n",
        "y-train: Training data label\n",
        "\n",
        "y_val  : Validation data label\n",
        "\n",
        "y_test : Testing data label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "CZvxGJk-rkkc"
      },
      "outputs": [],
      "source": [
        "from tkinter import YView\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# This function extracts data from .csv file and split into training, validation, and testing dataset.\n",
        "def data_extraction():\n",
        "  # Load the data from the messages.csv file.\n",
        "  df = pd.read_csv('messages.csv')\n",
        "\n",
        "  # Separate data into features and labels\n",
        "  x = df.message\n",
        "  y = df.label\n",
        "\n",
        "  # We first separate the entire dataset to 80% and 20%\n",
        "  # We use the 80% to get our training dataset and the validation dataset. \n",
        "  # We use the 20% as our testing dataset. \n",
        "  x_train_val, x_test, y_train_val, y_test = train_test_split(x, y, test_size=0.2, random_state=99, stratify = y)\n",
        "\n",
        "  # Separate the 80%, which contains our traning dataset and validation dataset, into another 80% traning dataset and 20% valications dataset.\n",
        "  x_train, x_val, y_train, y_val = train_test_split(x_train_val, y_train_val, test_size=0.2, random_state=99, stratify=y_train_val)\n",
        "\n",
        "  return x_train, x_val, x_test, y_train, y_val, y_test"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "inXlTIXTP6eG"
      },
      "source": [
        "With the code below, we extract the data for our use. \\\\\n",
        "\n",
        "**Run the code block below:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CP6CIbWYP51C",
        "outputId": "81528bb0-1ee4-4755-db21-7d7c739744ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2345    crossing boundaries : interdisciplinary approa...\n",
            "2664    this is not spam ; you are receiving this mess...\n",
            "1049    computational aspects of cognitive science nsf...\n",
            "1560    dear subscribers : the linguist list has just ...\n",
            "2167    i would like to know of sources for bengali so...\n",
            "                              ...                        \n",
            "2598    = 20 the virtual girlfriend and virtual boyfri...\n",
            "1310    learn to put angels to work ! angels are anoth...\n",
            "1906    call for papers sixth workshop on very large c...\n",
            "2286    for some time , i have been puzzled by a claim...\n",
            "191                       how to get on elsnet ? thanks\\n\n",
            "Name: message, Length: 1851, dtype: object 2648    0\n",
            "186     0\n",
            "940     0\n",
            "2127    0\n",
            "1051    0\n",
            "       ..\n",
            "1524    0\n",
            "1793    0\n",
            "323     0\n",
            "1111    0\n",
            "1204    0\n",
            "Name: label, Length: 463, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "X_train, X_val, X_test, Y_train, Y_val, Y_test = data_extraction()\n",
        "print(X_train, Y_val)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "nFUv7AmsFW8e"
      },
      "source": [
        "In the code block above, we have read the dataset into variables 'messages' and 'labels'. Variable 'messages' contains the email messages and variable 'labels' contains the class labels where 0 represents ham and 1 represents spam."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "v399Bk1sjKcA"
      },
      "source": [
        "We split the entire dataset into three different subsets: the training data, the validation data, and the testing data. \n",
        "\n",
        "In the code block above, we split the dataset twice using a 64:16:20 ratio, where 64% of the entire dataset is assigned to the training dataset (Y_train), 16% to the validation dataset (X_val), and 20% to the testing dataset (X_test), ."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Cn-R5V0HlFYm"
      },
      "source": [
        "### **Additional Information of Three Datasets**\n",
        "In the above operation, we divided the entire dataset into three parts: training dataset, validation dataset, and testing dataset. This is done to evaluate the performance of our machine learning model on new and unseen data. The training dataset is used to train the model, the validation dataset is used to tune the model's hyperparameters(magic words in our application), and the testing dataset is used to evaluate the final performance of the model. \n",
        "\n",
        "For more information on these concepts, you can read the article available at the following link: https://towardsdatascience.com/train-validation-and-test-sets-72cb40cba9e7."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "3KJ7iGauJih3"
      },
      "source": [
        "## **2. Preprocessing the Emails**\n",
        "To extract only useful information from the emails we used, we applied serveral data preprocessing steps.\n",
        "\n",
        "(1). We removed all HTML tags, numbers, punctuation marks, and English stop words. \n",
        "\n",
        "(2). We converted all words to their lowercase forms and combined each paragraph into a single line instead of multiple lines. \n",
        "\n",
        "(3). We conducted stemming on all the remaining words to reduce them to their root forms. \\\\\n",
        "\n",
        "**Run the code below:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZfS6VpTaH7Wu",
        "outputId": "bd60630f-4144-443a-e1a7-b5ac87134a7e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import nltk\n",
        "import string\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.feature_extraction._stop_words import ENGLISH_STOP_WORDS\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "\n",
        "# Download required packages from nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "# Define functions to clean up the text data.\n",
        "def remove_hyperlink(word):\n",
        "  return re.sub(r\"http\\S+\", \" \", word)\n",
        "\n",
        "# Convert the letter to lowercase.\n",
        "def to_lower(word):\n",
        "    result = word.lower()\n",
        "    return result\n",
        "\n",
        "# Remove the numbers.\n",
        "def remove_number(word):\n",
        "    result = re.sub(r'\\d+', ' ', word)\n",
        "    return result\n",
        "\n",
        "# Remove the puncturations.\n",
        "def remove_punctuation(word):\n",
        "    result = word.translate(str.maketrans(dict.fromkeys(string.punctuation)))\n",
        "    return result\n",
        "\n",
        "# Remove the whitespace. \n",
        "def remove_whitespace(word):\n",
        "    result = word.strip()\n",
        "    return result\n",
        "\n",
        "# Merge multiple lines into one line.\n",
        "def replace_newline(word):\n",
        "    return word.replace('\\n', ' ')\n",
        "\n",
        "\n",
        "def clean_up_pipeline(sentence):\n",
        "    cleaning_utils = [remove_hyperlink,replace_newline,to_lower, remove_number, remove_punctuation, remove_whitespace]\n",
        "    for o in cleaning_utils:\n",
        "        sentence = o(sentence)\n",
        "    return sentence\n",
        "\n",
        "# Remove the stopwords, for example: a, and, an, above, ..., etc.\n",
        "def remove_stop_words(words):\n",
        "    result = [i for i in words if i not in ENGLISH_STOP_WORDS]\n",
        "    return result\n",
        "\n",
        "# Reduce a word to its root word.\n",
        "def word_stemmer(words):\n",
        "    stemmer = PorterStemmer()\n",
        "    return [stemmer.stem(o) for o in words]\n",
        "\n",
        "# Remove inflectional endings only and to return the base.\n",
        "def word_lemmatizer(words):\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    return [lemmatizer.lemmatize(o) for o in words]\n",
        "\n",
        "# Clear out the unnecessary information.\n",
        "def clean_token_pipeline(words):\n",
        "    cleaning_utils = [remove_stop_words, word_lemmatizer]\n",
        "    for o in cleaning_utils:\n",
        "        words = o(words)\n",
        "    return words\n",
        "\n",
        " # Preprocess the text data.\n",
        "def preprocess(X_train, X_val, X_test):\n",
        "    x_train = [clean_up_pipeline(o) for o in X_train]\n",
        "    x_val = [clean_up_pipeline(o) for o in X_val]\n",
        "    x_test = [clean_up_pipeline(o) for o in X_test]\n",
        "\n",
        "    x_train = [word_tokenize(o) for o in x_train]\n",
        "    x_val = [word_tokenize(o) for o in x_val]\n",
        "    x_test = [word_tokenize(o) for o in x_test]\n",
        "\n",
        "    x_train = [clean_token_pipeline(o) for o in x_train]\n",
        "    x_val = [clean_token_pipeline(o) for o in x_val]\n",
        "    x_test = [clean_token_pipeline(o) for o in x_test]\n",
        "\n",
        "    x_train = [\" \".join(o) for o in x_train]\n",
        "    x_val = [\" \".join(o) for o in x_val]\n",
        "    x_test = [\" \".join(o) for o in x_test]    \n",
        "\n",
        "    return x_train, x_val, x_test\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "prHU5gB1Q_V-"
      },
      "source": [
        "With the code section below, we preprocess the dataset. \\\\\n",
        "**Run the code block below:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QoPue9h3Ik--",
        "outputId": "7bac73b8-5550-4a22-e291-9842dd5ecf45"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "crossing boundary interdisciplinary approach latin america th june nd july paper international conference aim explore contemporary cultural debate taking place latin america draw various strand debate multidisciplinary forum paper consider various issue modernization hybridity transculturation apply various field study paper welcome following field cultural study literature particularly looking trend contemporary narrative including neoavantgarde popular fiction drama study cinema gender study popular culture comparative literature anthropology ethnography sociology linguistics economics politics law symposium proposed far include exile latin american experience indigenismo negrismo u s latin america paper longer minute abstract word english spanish portuguese sent preferably email conference organiser department language cultural study university limerick ireland st january conference organizer nuala finnegan kate quinn nancy serrano department language cultural study university limerick limerick ireland tel fax email nuala finnegan ul kate quinn ul nancy serrano ul update visit webpage http www ul neylonm conf html mr michele j neylon department language cultural study university limerick limerick ireland tel http www ul neylonm index html\n"
          ]
        }
      ],
      "source": [
        "\n",
        "x_train, x_val, x_test = preprocess(X_train, X_val, X_test)\n",
        "print(x_train[0])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "N68YIZqIJmc8"
      },
      "source": [
        "## **3. Feature Extraction**\n",
        "In this step, we aim to transform the text content of an email into a numerical feature vector that captures the essential information used for classification. To achieve this, we can choose from a variety of vectorization techniques that convert text data into numerical vectors. \n",
        "\n",
        "In this lab, we will use TF-IDF and a modified Word2vec, as described in the papers. \\\\\n",
        "\n",
        "**Run the code block below:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wlpwcsgxJrMK",
        "outputId": "bb04ef84-a16e-441f-8f93-e9866b665bf9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (6.3.0)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.10.1)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.22.4)\n",
            "4.3.1\n"
          ]
        }
      ],
      "source": [
        "import gensim\n",
        "!pip install --upgrade gensim\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from gensim.models import Word2Vec\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy import sparse\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Print the version of gensim package\n",
        "print(gensim.__version__)\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "\n",
        "\n",
        "def convert_to_feature(raw_tokenize_data):\n",
        "    raw_sentences = [' '.join(o) for o in raw_tokenize_data]\n",
        "    print(raw_sentences[0])\n",
        "    print(raw_sentences[1])\n",
        "    return vectorizer.transform(raw_sentences)\n",
        "\n",
        "\n",
        "def TfidfConvert(x_train, x_test, x_val):\n",
        "    x_train = [o.split(\" \") for o in x_train]\n",
        "    x_test = [o.split(\" \") for o in x_test]\n",
        "    x_val = [o.split(\" \") for o in x_val]\n",
        "    x_train_raw_sentences = [' '.join(o) for o in x_train]\n",
        "    x_val_raw_sentences = [' '.join(o) for o in x_val]\n",
        "    raw_sentences = x_train_raw_sentences + x_val_raw_sentences\n",
        "    vectorizer.fit(raw_sentences)\n",
        "    x_train_features = convert_to_feature(x_train)\n",
        "    x_test_features = convert_to_feature(x_test)\n",
        "    x_val_features = convert_to_feature(x_val)\n",
        "\n",
        "    return x_train_features, x_test_features, x_val_features\n",
        "\n",
        "\n",
        "def getUniqueWords(allWords):\n",
        "    uniqueWords = []\n",
        "    for i in allWords:\n",
        "        if i not in uniqueWords:\n",
        "            uniqueWords.append(i)\n",
        "    return uniqueWords\n",
        "\n",
        "\n",
        "def input_split(x):\n",
        "    new_x = []\n",
        "    for line in x:\n",
        "        newline = line.split(' ')\n",
        "        new_x.append(newline)\n",
        "    return new_x\n",
        "\n",
        "\n",
        "def getUniqueWords(allWords):\n",
        "    uniqueWords = []\n",
        "    for i in allWords:\n",
        "        if i not in uniqueWords:\n",
        "            uniqueWords.append(i)\n",
        "    return uniqueWords\n",
        "\n",
        "\n",
        "def x2vec(input_x, feature_names, model):\n",
        "    x_features = []\n",
        "    for index in input_x:\n",
        "        model_vector = [0] * len(feature_names)\n",
        "\n",
        "        for token in index:\n",
        "            if token in feature_names:\n",
        "                feature_index = feature_names.index(token)\n",
        "\n",
        "                if model.wv.has_index_for(token):\n",
        "                    token_vecs = model.wv.get_vector(token)\n",
        "                    model_vector[feature_index] = token_vecs[0]\n",
        "        x_features.append(model_vector)\n",
        "    return x_features\n",
        "\n",
        "\n",
        "def single_transform(x, method, feature_model, feature_names, scaler, selection_model):\n",
        "    if method == 'TFIDF':\n",
        "\n",
        "        result = feature_model.transform(x)\n",
        "        if selection_model != 'NaN':\n",
        "            result = selection_model.transform(result)\n",
        "        return result\n",
        "    else:\n",
        "        temp_x = x.values\n",
        "        temp_x = temp_x[0].split(' ')\n",
        "        model_vector = [0] * len(feature_names)\n",
        "        for token in temp_x:\n",
        "            if token in feature_names:\n",
        "                feature_index = feature_names.index(token)\n",
        "                if feature_model.wv.has_index_for(token):\n",
        "                    token_vecs = feature_model.wv.get_vector(token)\n",
        "                    model_vector[feature_index] = token_vecs[0]\n",
        "        x_features = [model_vector]\n",
        "        # x_features = np.array(x_features)\n",
        "        x_features = scaler.transform(x_features)\n",
        "        x_train_features = sparse.csr_matrix(x_features)\n",
        "        if selection_model != 'NaN':\n",
        "            x_train_features = selection_model.transform(x_train_features)\n",
        "        return x_train_features\n",
        "\n",
        "\n",
        "def feature_extraction(x_train, x_test, x_val, method):\n",
        "\n",
        "    if method == 'TFIDF':\n",
        "        x_train_features, x_test_features, x_val_features = TfidfConvert(x_train, x_test, x_val)\n",
        "        feature_names = vectorizer.get_feature_names_out()\n",
        "\n",
        "        return x_train_features, x_test_features, x_val_features, feature_names, vectorizer, 'NaN'\n",
        "\n",
        "    if method == 'word2vec':\n",
        "        temp_x_train = input_split(x_train)\n",
        "        temp_x_test = input_split(x_test)\n",
        "        temp_x_val = input_split(x_val)\n",
        "\n",
        "        model_train = Word2Vec(temp_x_train, vector_size=1)\n",
        "        feature_space = []\n",
        "        for index in temp_x_train:\n",
        "            feature_space = feature_space + getUniqueWords(index)\n",
        "        feature_names = getUniqueWords(feature_space)\n",
        "      \n",
        "        x_train_features = x2vec(temp_x_train, feature_names, model_train)\n",
        "        x_test_features = x2vec(temp_x_test, feature_names, model_train)\n",
        "        x_val_features = x2vec(temp_x_val, feature_names, model_train)\n",
        "\n",
        "        x_train_features = np.array(x_train_features)\n",
        "        x_test_features = np.array(x_test_features)\n",
        "        x_val_features = np.array(x_val_features)\n",
        "\n",
        "        pd.DataFrame(x_train_features).to_csv(\"x_train_features.csv\", header=None, index=False)\n",
        "        pd.DataFrame(x_test_features).to_csv(\"x_test_features.csv\", header=None, index=False)\n",
        "        pd.DataFrame(x_val_features).to_csv(\"x_val_features.csv\", header=None, index=False)\n",
        "\n",
        "        scaler = MinMaxScaler()\n",
        "        scaler.fit(x_train_features)\n",
        "        x_train_features = scaler.transform(x_train_features)\n",
        "        x_test_features = scaler.transform(x_test_features)\n",
        "        x_val_features = scaler.transform(x_val_features)\n",
        "\n",
        "        x_train_features = sparse.csr_matrix(x_train_features)\n",
        "        x_test_features = sparse.csr_matrix(x_test_features)\n",
        "        x_val_features = sparse.csr_matrix(x_val_features)\n",
        "\n",
        "        return x_train_features, x_test_features, x_val_features, feature_names, model_train, scaler\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Cn5SDg6FRJxK"
      },
      "source": [
        "For example, with the code below, we extract the TFIDF values of all the emails in a dataset. \\\\\n",
        "**Run the code block below:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HzIT4gP1RWX4",
        "outputId": "d9982522-a718-4690-c65d-e3e1e6c199b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  (0, 0)\t1.0\n",
            "  (0, 1)\t1.0\n",
            "  (0, 2)\t1.0\n",
            "  (0, 3)\t0.9999999999999999\n",
            "  (0, 4)\t1.0\n",
            "  (0, 5)\t1.0\n",
            "  (0, 6)\t1.0\n",
            "  (0, 7)\t1.0\n",
            "  (0, 8)\t1.0\n",
            "  (0, 9)\t1.0\n",
            "  (0, 10)\t1.0\n",
            "  (0, 11)\t1.0\n",
            "  (0, 12)\t1.0\n",
            "  (0, 13)\t1.0\n",
            "  (0, 14)\t1.0\n",
            "  (0, 15)\t1.0\n",
            "  (0, 16)\t1.0\n",
            "  (0, 17)\t1.0\n",
            "  (0, 18)\t0.9999999999999999\n",
            "  (0, 19)\t0.9999999999999999\n",
            "  (0, 20)\t1.0\n",
            "  (0, 21)\t0.9999999999999999\n",
            "  (0, 22)\t1.0\n",
            "  (0, 23)\t1.0\n",
            "  (0, 24)\t1.0\n",
            "  :\t:\n",
            "  (0, 36004)\t1.0\n",
            "  (0, 36036)\t1.0\n",
            "  (0, 36054)\t1.0\n",
            "  (0, 36284)\t1.0\n",
            "  (0, 36467)\t1.0\n",
            "  (0, 36654)\t1.0\n",
            "  (0, 36742)\t1.0\n",
            "  (0, 36744)\t1.0\n",
            "  (0, 36751)\t1.0\n",
            "  (0, 36935)\t1.0\n",
            "  (0, 36989)\t1.0\n",
            "  (0, 37739)\t1.0\n",
            "  (0, 37748)\t1.0\n",
            "  (0, 37757)\t1.0\n",
            "  (0, 38812)\t1.0\n",
            "  (0, 38816)\t1.0\n",
            "  (0, 38821)\t1.0\n",
            "  (0, 39097)\t1.0\n",
            "  (0, 39100)\t1.0\n",
            "  (0, 39129)\t1.0\n",
            "  (0, 39194)\t1.0\n",
            "  (0, 40203)\t1.0\n",
            "  (0, 40747)\t0.9999999999999999\n",
            "  (0, 40802)\t1.0\n",
            "  (0, 41293)\t1.0\n"
          ]
        }
      ],
      "source": [
        "\n",
        "method = \"word2vec\"\n",
        "x_train_features, x_test_features, x_val_features, feature_names, feature_model, scalar = feature_extraction(x_train, x_test, x_val, method)\n",
        "print(x_train_features[0])\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "MND-TjQRXkpq"
      },
      "source": [
        "### **Question 1**\n",
        "Look up the information of Word2vec online and describe what it does in your own words using one short paragraph.\n",
        "Ans: Word2Vec is a powerful natural language processing technique that leverages neural networks to learn distributed vector representations for words in a text corpus. By training on large datasets, Word2Vec captures the semantic relationships and contextual similarities between words, mapping them to a multi-dimensional vector space. These dense vector representations can then be used as input features for various machine learning and text analysis tasks,  ultimately enhancing the performance of these models by incorporating the rich semantic information learned by Word2Vec."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "TAbh0HSVrCQd"
      },
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "k0RZeCBFLSH9"
      },
      "source": [
        "## **4. Training SVM Classifiers**\n",
        "In this section, we will train a Support Vector Machine (SVM) as an spam filter. \\\\\n",
        "\n",
        "**Run the code block below:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kAeBdHNfLM7k",
        "outputId": "1d070bb5-826c-44e9-c2db-66c8ce509f60"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting secml\n",
            "  Downloading secml-0.15.6-py3-none-any.whl (463 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m464.0/464.0 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from secml) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from secml) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from secml) (1.10.1)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from secml) (1.2.0)\n",
            "Requirement already satisfied: matplotlib>=3 in /usr/local/lib/python3.10/dist-packages (from secml) (3.7.1)\n",
            "Requirement already satisfied: Pillow>=6.2.1 in /usr/local/lib/python3.10/dist-packages (from secml) (8.4.0)\n",
            "Requirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.10/dist-packages (from secml) (1.2.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from secml) (2.27.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->secml) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->secml) (0.11.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->secml) (1.0.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->secml) (23.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->secml) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->secml) (1.4.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil->secml) (1.16.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22->secml) (3.1.0)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->secml) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->secml) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->secml) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->secml) (2022.12.7)\n",
            "Installing collected packages: secml\n",
            "Successfully installed secml-0.15.6\n",
            "2023-05-04 01:53:48,354 - secml.settings - INFO - New `SECML_HOME_DIR` created: /root/secml-data\n",
            "2023-05-04 01:53:48,354 - secml.settings - INFO - New `SECML_HOME_DIR` created: /root/secml-data\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:secml.settings:New `SECML_HOME_DIR` created: /root/secml-data\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-05-04 01:53:48,380 - secml.settings - INFO - Default configuration file copied to: /root/secml-data/secml.conf\n",
            "2023-05-04 01:53:48,380 - secml.settings - INFO - Default configuration file copied to: /root/secml-data/secml.conf\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:secml.settings:Default configuration file copied to: /root/secml-data/secml.conf\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-05-04 01:53:48,402 - secml.settings - INFO - New `SECML_DS_DIR` created: /root/secml-data/datasets\n",
            "2023-05-04 01:53:48,402 - secml.settings - INFO - New `SECML_DS_DIR` created: /root/secml-data/datasets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:secml.settings:New `SECML_DS_DIR` created: /root/secml-data/datasets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-05-04 01:53:48,422 - secml.settings - INFO - New `SECML_MODELS_DIR` created: /root/secml-data/models\n",
            "2023-05-04 01:53:48,422 - secml.settings - INFO - New `SECML_MODELS_DIR` created: /root/secml-data/models\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:secml.settings:New `SECML_MODELS_DIR` created: /root/secml-data/models\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-05-04 01:53:48,440 - secml.settings - INFO - New `SECML_EXP_DIR` created: /root/secml-data/experiments\n",
            "2023-05-04 01:53:48,440 - secml.settings - INFO - New `SECML_EXP_DIR` created: /root/secml-data/experiments\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:secml.settings:New `SECML_EXP_DIR` created: /root/secml-data/experiments\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-05-04 01:53:48,463 - secml.settings - INFO - New `SECML_LOGS_DIR` created: /root/secml-data/logs\n",
            "2023-05-04 01:53:48,463 - secml.settings - INFO - New `SECML_LOGS_DIR` created: /root/secml-data/logs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:secml.settings:New `SECML_LOGS_DIR` created: /root/secml-data/logs\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-05-04 01:53:48,484 - secml.settings - INFO - New `SECML_PYTORCH_DIR` created: /root/secml-data/pytorch-data\n",
            "2023-05-04 01:53:48,484 - secml.settings - INFO - New `SECML_PYTORCH_DIR` created: /root/secml-data/pytorch-data\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:secml.settings:New `SECML_PYTORCH_DIR` created: /root/secml-data/pytorch-data\n"
          ]
        }
      ],
      "source": [
        "!pip install secml\n",
        "from secml.data import CDataset\n",
        "from secml.data.splitter import CDataSplitterKFold\n",
        "from secml.ml.classifiers import CClassifierSVM\n",
        "from secml.ml.peval.metrics import CMetricAccuracy\n",
        "from secml.ml.peval.metrics import CMetricConfusionMatrix\n",
        "from secml.adv.attacks.evasion import CAttackEvasionPGD\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "# from Feature_extraction import single_transform\n",
        "import csv\n",
        "from statistics import mean, stdev\n",
        "import threading\n",
        "import time\n",
        "\n",
        "\n",
        "def train_SVM(x_train_features, x_val_features, y_train, y_val):\n",
        "    tr_set = CDataset(x_train_features, y_train)\n",
        "    # Train the SVM\n",
        "    print(\"Build SVM\")\n",
        "    xval_splitter = CDataSplitterKFold()\n",
        "    clf_lin = CClassifierSVM()\n",
        "    xval_lin_params = {'C': [1]}\n",
        "    print(\"Find the best params\")\n",
        "    best_lin_params = clf_lin.estimate_parameters(\n",
        "        dataset=tr_set,\n",
        "        parameters=xval_lin_params,\n",
        "        splitter=xval_splitter,\n",
        "        metric='accuracy',\n",
        "        perf_evaluator='xval'\n",
        "    )\n",
        "    print(\"Finish Train\")\n",
        "    print(\"The best training parameters are: \", [\n",
        "          (k, best_lin_params[k]) for k in sorted(best_lin_params)])\n",
        "    print(\"Train SVM\")\n",
        "    clf_lin.fit(tr_set.X, tr_set.Y)\n",
        "\n",
        "    # Test the Classifier\n",
        "    v_set = CDataset(x_val_features, y_val)\n",
        "    y_pred = clf_lin.predict(v_set.X)\n",
        "    metric = CMetricAccuracy()\n",
        "    acc = metric.performance_score(y_true=v_set.Y, y_pred=y_pred)\n",
        "    confusion_matrix = CMetricConfusionMatrix()\n",
        "    cm = confusion_matrix.performance_score(y_true=v_set.Y, y_pred=y_pred)\n",
        "    print(\"Confusion Matrix: \")\n",
        "    print(cm)\n",
        "\n",
        "\n",
        "    return tr_set, v_set, clf_lin"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "G0cZ1mqaRl7k"
      },
      "source": [
        "For example, with the code section below, we train an SVM classifier using the TFIDF values extracted. \\\\\n",
        "\n",
        "**Run the code block below:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8TcGiCZJRmfo",
        "outputId": "7f38afd3-7249-4eb1-fa2d-73ecad5c1467"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Build SVM\n",
            "Find the best params\n",
            "Finish Train\n",
            "The best training parameters are:  [('C', 1)]\n",
            "Train SVM\n",
            "Confusion Matrix: \n",
            "CArray([[385   1]\n",
            " [  4  73]])\n"
          ]
        }
      ],
      "source": [
        "tr_set, v_set, clf_lin = train_SVM(x_train_features, x_val_features, Y_train, Y_val)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "5rKjzZTCO5N2"
      },
      "source": [
        "## **5. PGD Attack**\n",
        "Our approach is based on successful adversarial perturbations made to model input features. We employ the Projected Gradient Descent (PGD) method to modify numeric feature values in the feature domain. PGD algorithm iteratively finds the needed changes with a constraint, *dmax*, which is the Euclidean distance to the original features indicating the allowed level of perturbations, to achieve the maximum loss in classification. In our approach, we run PGD over a set of spam emails and generate adversarial examples. Then we test these modified feature vectors to see whether they could successfully bypass the detection (i.e., being classified as ham). \\\\\n",
        "\n",
        "**Run the code block below:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "lCvPfWA-P1OG"
      },
      "outputs": [],
      "source": [
        "def pgd_attack(clf_lin, tr_set, v_set, y_val, feature_names, nb_attack, dmax, lb, ub):\n",
        "\n",
        "    class_to_attack = 1\n",
        "    cnt = 0  # the number of success adversaril examples\n",
        "\n",
        "    ori_examples2_x = []\n",
        "    ori_examples2_y = []\n",
        "\n",
        "    for i in range(nb_attack):\n",
        "        # take a point at random being the starting point of the attack\n",
        "        idx_candidates = np.where(y_val == class_to_attack)\n",
        "        # select nb_init_pts points randomly in candidates and make them move\n",
        "        rn = np.random.choice(idx_candidates[0].size, 1)\n",
        "        x0, y0 = v_set[idx_candidates[0][rn[0]], :].X, v_set[idx_candidates[0][rn[0]], :].Y\n",
        "\n",
        "        x0 = x0.astype(float)\n",
        "        y0 = y0.astype(int)\n",
        "        x2 = x0.tondarray()[0]\n",
        "        y2 = y0.tondarray()[0]\n",
        "\n",
        "        ori_examples2_x.append(x2)\n",
        "        ori_examples2_y.append(y2)\n",
        "\n",
        "    # Perform adversarial attacks\n",
        "    noise_type = 'l2'  # Type of perturbation 'l1' or 'l2'\n",
        "    y_target = 0\n",
        "    # dmax = 0.09  # Maximum perturbation\n",
        "\n",
        "    # Bounds of the attack space. Can be set to `None` for unbounded\n",
        "    solver_params = {\n",
        "        'eta': 0.01,\n",
        "        'max_iter': 1000,\n",
        "        'eps': 1e-4}\n",
        "\n",
        "    # set lower bound and upper bound respectively to 0 and 1 since all features are Boolean\n",
        "    pgd_attack = CAttackEvasionPGD(\n",
        "        classifier=clf_lin,\n",
        "        double_init_ds=tr_set,\n",
        "        distance=noise_type,\n",
        "        dmax=dmax,\n",
        "        lb=lb, ub=ub,\n",
        "        solver_params=solver_params,\n",
        "        y_target=y_target\n",
        "    )\n",
        "\n",
        "    ad_examples_x = []\n",
        "    ad_examples_y = []\n",
        "    ad_index = []\n",
        "    cnt = 0\n",
        "    for i in range(len(ori_examples2_x)):\n",
        "        x0 = ori_examples2_x[i]\n",
        "        y0 = ori_examples2_y[i]\n",
        "        y_pred_pgd, _, adv_ds_pgd, _ = pgd_attack.run(x0, y0)\n",
        "        if y_pred_pgd.item() == 0:\n",
        "            cnt = cnt + 1\n",
        "            ad_index.append(i)\n",
        "\n",
        "        ad_examples_x.append(adv_ds_pgd.X.tondarray()[0])\n",
        "        ad_examples_y.append(y_pred_pgd.item())\n",
        "\n",
        "        attack_pt = adv_ds_pgd.X.tondarray()[0]\n",
        "    print(\"\\tPGD attack successful rate:\", cnt / nb_attack)\n",
        "    startTime2 = time.time()\n",
        "    ori_examples2_x = np.array(ori_examples2_x)\n",
        "    ori_examples2_y = np.array(ori_examples2_y)\n",
        "    ad_examples_x = np.array(ad_examples_x)\n",
        "    ad_examples_y = np.array(ad_examples_y)\n",
        "\n",
        "    ori_dataframe = pd.DataFrame(ori_examples2_x, columns=feature_names)\n",
        "    ad_dataframe = pd.DataFrame(ad_examples_x, columns=feature_names)\n",
        "\n",
        "    # extract the success and fail examples\n",
        "    ad_dataframe['ad_label'] = ad_examples_y\n",
        "    ad_success = ad_dataframe.loc[ad_dataframe.ad_label == 0]\n",
        "    ori_success = ori_dataframe.loc[ad_dataframe.ad_label == 0]\n",
        "    ad_fail = ad_dataframe.loc[ad_dataframe.ad_label == 1]\n",
        "    ori_fail = ori_dataframe.loc[ad_dataframe.ad_label == 1]\n",
        "\n",
        "    ad_success_x = ad_success.drop(columns=['ad_label'])\n",
        "    ad_fail_x = ad_fail.drop(columns=['ad_label'])\n",
        "\n",
        "    result = (ad_success_x - ori_success)\n",
        "    ori_dataframe.to_csv('ori_dataframe.csv')\n",
        "    ad_dataframe.to_csv('ad_dataframe.csv')\n",
        "    result.to_csv('result.csv')\n",
        "    \n",
        "    return result, cnt, ad_success_x, ori_dataframe, ori_examples2_y, cnt/nb_attack"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "f3qmM8uxrzrg"
      },
      "source": [
        "With the code section below, we run PGD attacks on the trained classifier with 100 spam emails and 0.06 for dmax. \\\\\n",
        "\n",
        "**Run the code block below:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_RYKIvm0QMHD",
        "outputId": "ea721dbf-b985-47d7-9817-786ac467cf4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tPGD attack successful rate: 0.1\n"
          ]
        }
      ],
      "source": [
        "lb = np.ndarray.min(x_train_features.toarray())\n",
        "ub = np.ndarray.max(x_train_features.toarray())\n",
        "attack_amount = 100\n",
        "dmax = 0.02\n",
        "result, cnt, ad_success_x, ori_dataframe, ori_examples2_y, successful_rate = pgd_attack(clf_lin, tr_set, v_set, Y_val, feature_names, attack_amount, dmax, lb, ub)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "7xUx6FBQiCBr"
      },
      "source": [
        "## **6. Magical Words**\n",
        "Adversarial emails are crafted by adding “magic words” to the original spam emails. The “magic words” are identified by intersecting the unique ham words with the “top words” identified during the adversarial perturbations. Specifically, the unique ham words are the words that only appear in ham emails but not in spam emails. After the PGD attack on the set of spam emails, we find which features are modified to the largest extent to bypass the detection. We then select a list of “top words” whose feature values have been changed the most. (The changes are measured by the variance of differences before and after the PGD perturbation.) In our experiments, we use the top 100 words, which is efficient. This set is relatively small and demonstrates a high success rate with the resulting magic words to fool the classifier. \\\\\n",
        "\n",
        "**Run the code block below:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Mc552xOTSQZn"
      },
      "outputs": [],
      "source": [
        "def magical_word(x_train, x_val, y_train, y_val, result, cnt):\n",
        "    # Method 2\n",
        "    x2result1 = result\n",
        "    x2result1 = np.array(x2result1)\n",
        "    x2result = result\n",
        "    x2result = x2result.multiply(x2result1)\n",
        "\n",
        "    sum_number = x2result.sum() / cnt\n",
        "    sum_number = pd.DataFrame(sum_number, columns=['sum_number'])\n",
        "    sum_number = sum_number.sort_values(\n",
        "        by='sum_number', ascending=False, inplace=False)\n",
        "\n",
        "    sum_number_pd = pd.DataFrame(sum_number.index[:100])\n",
        "    sum_number_pd.to_csv(\"x2result.csv\")\n",
        "    d = {'message': x_train, 'label': y_train}\n",
        "    df = pd.DataFrame(data=d)\n",
        "    d1 = {'message': x_val, 'label': y_val}\n",
        "    df1 = pd.DataFrame(data=d1)\n",
        "    frames = [df, df1]\n",
        "    messages = pd.concat(frames)\n",
        "    messages.to_csv(\"messages (4).csv\")\n",
        "    spam = messages[messages.label == 1]\n",
        "    ham = messages[messages.label == 0]\n",
        "\n",
        "    # Tf-idf for spam datasets\n",
        "    vect_spam = TfidfVectorizer()\n",
        "    vect_spam.fit_transform(spam['message'])\n",
        "    header_spam = vect_spam.get_feature_names_out()\n",
        "\n",
        "    # Tf-idf for ham datasets\n",
        "    vect_ham = TfidfVectorizer()\n",
        "    vect_ham.fit_transform(ham['message'])\n",
        "    header_ham = vect_ham.get_feature_names_out()\n",
        "\n",
        "    # find unique ham words\n",
        "    ham_unique = list(set(header_ham).difference(set(header_spam)))\n",
        "    header_ham1 = pd.DataFrame(ham_unique)\n",
        "    header_ham1.to_csv(\"ham_unique.csv\")\n",
        "\n",
        "    with open(\"x2result.csv\", \"r\") as csvfile:\n",
        "        reader = csv.reader(csvfile)\n",
        "        top100_features = []\n",
        "        for row in reader:\n",
        "            top100_features.append(row[1])\n",
        "    top100_features = top100_features[1:]\n",
        "    # in ham & top100\n",
        "\n",
        "    ham_unique_in_top = list(\n",
        "        set(ham_unique).intersection(set(top100_features)))\n",
        "    words14str = \"\"\n",
        "    for item in ham_unique_in_top:\n",
        "        words14str = words14str + \" \" + item\n",
        "    return words14str, spam, ham"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "LjldI2rTs_N5"
      },
      "source": [
        "With the code section below, we identify a set of magic words. \\\\\n",
        "\n",
        "**Run the code block below:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4yC_GNgts8UO",
        "outputId": "a3a78bd2-5ea8-421b-d6b9-42d2c01ac43f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " thierry directeur pp linguistic titus linguist np colleague isbn restrictive generative sept elsnet clermont posting corpus lexical constraint dissertation query universiti belgium professeur pdf programme grammar\n"
          ]
        }
      ],
      "source": [
        "words14str, spam, ham = magical_word(X_train, X_val, Y_train, Y_val, result, cnt)\n",
        "print(words14str)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "d9e3VAwouiQK"
      },
      "source": [
        "## **7. Crafting Adversarial Emails & Attacking SVM**\n",
        "We can insert the identified \"magic words\" to original spam emails. This proccess is what we called \"crafting adversarial emails\". Then, we feed the new feature vectors of these crafted emails to the SVM classifier to see if they can be misclassified as ham emails.  \\\\\n",
        "\n",
        "**Run the code block below:**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "PxY8tJakw2yv"
      },
      "outputs": [],
      "source": [
        "m2_empty = pd.DataFrame()\n",
        "spam_cnt = 0\n",
        "threads = []\n",
        "m2_empty_l1 = pd.DataFrame()\n",
        "m2_empty_l2 = pd.DataFrame()\n",
        "m2_empty_l3 = pd.DataFrame()\n",
        "m2_empty_l4 = pd.DataFrame()\n",
        "m2_list = [m2_empty_l1, m2_empty_l2, m2_empty_l3, m2_empty_l4]\n",
        "\n",
        "class myThread(threading.Thread):\n",
        "\n",
        "    def __init__(self, threadID, name, spam_message, words14str, method, feature_model, feature_names, scaler, clf_lin, list_index, selection_model):\n",
        "        threading.Thread.__init__(self)\n",
        "        self.threadID = threadID\n",
        "        self.name = name\n",
        "        self.spam_message = spam_message\n",
        "        self.words14str = words14str\n",
        "        self.method = method\n",
        "        self.feature_model = feature_model\n",
        "        self.feature_names = feature_names\n",
        "        self.scaler = scaler\n",
        "        self.clf_lin = clf_lin\n",
        "        self.list_index = list_index\n",
        "        self.lock = threading.Lock()\n",
        "        self.selection_model = selection_model\n",
        "\n",
        "    def run(self):\n",
        "        global spam_cnt\n",
        "        spam_cnt = 0\n",
        "        print(\"Starting \" + self.name, spam_cnt)\n",
        "        spam_cnt_1 = m2_empty_out(self.name, self.spam_message, self.words14str, self.method,\n",
        "                                  self.feature_model, self.feature_names, self.scaler, self.clf_lin,\n",
        "                                  self.list_index, self.selection_model)\n",
        "        spam_cnt = spam_cnt+spam_cnt_1\n",
        "        time.sleep(0.1)\n",
        "        print(\"Exiting \" + self.name, spam_cnt)\n",
        "\n",
        "\n",
        "def m2_empty_out(name, spam_message, words14str, method, feature_model, feature_names, scaler, clf_lin, list_index, selection_model):\n",
        "    m2_empty_1 = pd.DataFrame()\n",
        "    spam_cnt_1 = 0\n",
        "    global m2_list\n",
        "\n",
        "    for j in spam_message.message:\n",
        "        choose_email = [j + words14str]\n",
        "        message_14_email = pd.DataFrame(choose_email, columns=[\"message\"])\n",
        "        message_14_tf_idf = single_transform(\n",
        "            message_14_email[\"message\"], method, feature_model, feature_names, scaler, selection_model)\n",
        "        message_14_tf_idf = pd.DataFrame(\n",
        "            message_14_tf_idf.toarray(), columns=feature_names)\n",
        "        message_14_y = [1]\n",
        "        message_14_y = pd.Series(message_14_y)\n",
        "        message_CData = CDataset(message_14_tf_idf, message_14_y)\n",
        "        message_14_pred = clf_lin.predict(message_CData.X)\n",
        "\n",
        "        if message_14_pred == 0:\n",
        "            spam_cnt_1 = spam_cnt_1 + 1\n",
        "            m2_empty_1 = m2_empty_1.append(\n",
        "                message_14_tf_idf, ignore_index=True)\n",
        "\n",
        "    m2_list[list_index] = m2_list[list_index].append(\n",
        "        m2_empty_1, ignore_index=True)\n",
        "\n",
        "    return spam_cnt_1\n",
        "\n",
        "\n",
        "\n",
        "def svm_attack(method, clf_lin, spam, words14str, feature_model, feature_names, scaler, selection_model):\n",
        "\n",
        "    global m2_empty\n",
        "\n",
        "    # Clear the global threads list\n",
        "    threads.clear()\n",
        "\n",
        "    spam_messages = np.array_split(spam, 4)\n",
        "    print(\"Start processing message\")\n",
        "    thread1 = myThread(1, \"Thread-1\", spam_messages[0], words14str,\n",
        "                       method, feature_model, feature_names, scaler, clf_lin, 0, selection_model)\n",
        "    thread2 = myThread(2, \"Thread-2\", spam_messages[1], words14str,\n",
        "                       method, feature_model, feature_names, scaler, clf_lin, 1, selection_model)\n",
        "    thread3 = myThread(3, \"Thread-3\", spam_messages[2], words14str,\n",
        "                       method, feature_model, feature_names, scaler, clf_lin, 2, selection_model)\n",
        "    thread4 = myThread(4, \"Thread-4\", spam_messages[3], words14str,\n",
        "                       method, feature_model, feature_names, scaler, clf_lin, 3, selection_model)\n",
        "    threads.append(thread1)\n",
        "    threads.append(thread2)\n",
        "    threads.append(thread3)\n",
        "    threads.append(thread4)\n",
        "    for t in threads:\n",
        "        t.start()\n",
        "    for t in threads:\n",
        "        t.join()\n",
        "\n",
        "    m2_empty = m2_empty.append(m2_list[0], ignore_index=True)\n",
        "    m2_empty = m2_empty.append(m2_list[1], ignore_index=True)\n",
        "    m2_empty = m2_empty.append(m2_list[2], ignore_index=True)\n",
        "    m2_empty = m2_empty.append(m2_list[3], ignore_index=True)\n",
        "\n",
        "    print(\"Exiting Main Thread\")\n",
        "    print('White box attack with length on SVM:')\n",
        "    print('Number of samples provided:', len(spam))\n",
        "    print('Number of crafted sample that got misclassified:', spam_cnt)\n",
        "    print('Successful rate:', spam_cnt / len(spam))\n",
        "\n",
        "    return m2_empty"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "raxGc9-UsT6d"
      },
      "source": [
        "With the code below, we craft a set of spam emails and feed them to the trained classifier for testing. It prints out the success rate of this attack.\\\\\n",
        "\n",
        "**Run the code block below:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yo5YVW5zw0Iu",
        "outputId": "504c0f58-635d-429d-cc98-f73b9ba1e316"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception in thread Thread-2:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "Exception in thread Exception in thread Thread-1:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"<ipython-input-15-53fdc3872ad4>\", line 31, in run\n",
            "    self.run()\n",
            "  File \"<ipython-input-15-53fdc3872ad4>\", line 31, in run\n",
            "Thread-3:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "  File \"<ipython-input-15-53fdc3872ad4>\", line 47, in m2_empty_out\n",
            "  File \"<ipython-input-7-6cdd3bf5f823>\", line 81, in single_transform\n",
            "AttributeError: 'Word2Vec' object has no attribute 'transform'\n",
            "  File \"<ipython-input-15-53fdc3872ad4>\", line 47, in m2_empty_out\n",
            "  File \"<ipython-input-7-6cdd3bf5f823>\", line 81, in single_transform\n",
            "AttributeError: 'Word2Vec' object has no attribute 'transform'\n",
            "    self.run()\n",
            "  File \"<ipython-input-15-53fdc3872ad4>\", line 31, in run\n",
            "  File \"<ipython-input-15-53fdc3872ad4>\", line 47, in m2_empty_out\n",
            "  File \"<ipython-input-7-6cdd3bf5f823>\", line 81, in single_transform\n",
            "AttributeError: 'Word2Vec' object has no attribute 'transform'\n",
            "Exception in thread Thread-4:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"<ipython-input-15-53fdc3872ad4>\", line 31, in run\n",
            "  File \"<ipython-input-15-53fdc3872ad4>\", line 47, in m2_empty_out\n",
            "  File \"<ipython-input-7-6cdd3bf5f823>\", line 81, in single_transform\n",
            "AttributeError: 'Word2Vec' object has no attribute 'transform'\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:94: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty = m2_empty.append(m2_list[0], ignore_index=True)\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty = m2_empty.append(m2_list[1], ignore_index=True)\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:96: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty = m2_empty.append(m2_list[2], ignore_index=True)\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:97: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty = m2_empty.append(m2_list[3], ignore_index=True)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start processing message\n",
            "Starting Thread-1 0\n",
            "Starting Thread-2 0\n",
            "Starting Thread-3 0\n",
            "Starting Thread-4 0\n",
            "Exiting Main Thread\n",
            "White box attack with length on SVM:\n",
            "Number of samples provided: 385\n",
            "Number of crafted sample that got misclassified: 0\n",
            "Successful rate: 0.0\n"
          ]
        }
      ],
      "source": [
        "m2_empty = svm_attack('TFIDF', clf_lin, spam, words14str, feature_model, feature_names, scalar, 'NaN')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "-KIQP6h8VzVq"
      },
      "source": [
        "## **Tasks**\n",
        "### **Task 1** ### \n",
        "Integrate the steps 1-7 above into one function in the below code block.\n",
        "This function only has two inputs, with the method for feature extraction and the dmax we would use for PGD attacks. This function should return the set of magic words identified and print out the success rate in step 7. \\\\\n",
        "\n",
        "Hint: You can change the method of feature extraction by changing the value of the \"method\" variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "penr97JhaHgq",
        "outputId": "57c0342f-36d9-47c1-ccda-707207be8c38"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Build SVM\n",
            "Find the best params\n",
            "Finish Train\n",
            "The best training parameters are:  [('C', 1)]\n",
            "Train SVM\n",
            "Confusion Matrix: \n",
            "CArray([[385   1]\n",
            " [  4  73]])\n",
            "\tPGD attack successful rate: 0.07\n",
            "Start processing message\n",
            "Starting Thread-1Starting Thread-2 0 0\n",
            "\n",
            "Starting Thread-3 0\n",
            "Starting Thread-4 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:61: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_list[list_index] = m2_list[list_index].append(\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exiting Thread-1 55\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:61: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_list[list_index] = m2_list[list_index].append(\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exiting Thread-2 111\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:61: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_list[list_index] = m2_list[list_index].append(\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exiting Thread-3 171\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty_1 = m2_empty_1.append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:61: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_list[list_index] = m2_list[list_index].append(\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:94: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty = m2_empty.append(m2_list[0], ignore_index=True)\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty = m2_empty.append(m2_list[1], ignore_index=True)\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:96: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty = m2_empty.append(m2_list[2], ignore_index=True)\n",
            "\n",
            "WARNING:py.warnings:<ipython-input-15-53fdc3872ad4>:97: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  m2_empty = m2_empty.append(m2_list[3], ignore_index=True)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exiting Thread-4 221\n",
            "Exiting Main Thread\n",
            "White box attack with length on SVM:\n",
            "Number of samples provided: 385\n",
            "Number of crafted sample that got misclassified: 221\n",
            "Successful rate: 0.574025974025974\n",
            "Magic words:  thierry directeur pp linguistic titus linguist colleague isbn restrictive generative elsnet posting corpus lexical constraint dissertation query belgium professeur pdf programme grammar\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.svm import SVC\n",
        "from secml.adv.attacks import CAttackEvasionPGD\n",
        "from secml.array import CArray\n",
        "from secml.data import CDataset\n",
        "from secml.ml.classifiers import CClassifierSVM\n",
        "from secml.ml.peval.metrics import CMetricAccuracy\n",
        "\n",
        "def magic_word_attack(method, dmax):\n",
        "    # Load data and preprocess\n",
        "    X_train, X_val, X_test, Y_train, Y_val, Y_test = data_extraction()\n",
        "    x_train, x_val, x_test = preprocess(X_train, X_val, X_test)\n",
        "    # Feature extraction\n",
        "  \n",
        "    x_train_features, x_test_features, x_val_features, feature_names, feature_model, scalar = feature_extraction(x_train, x_test, x_val, method)   \n",
        "\n",
        "   \n",
        "\n",
        "    # Train the classifier\n",
        "    tr_set, v_set, clf_lin = train_SVM(x_train_features, x_val_features, Y_train, Y_val)\n",
        "\n",
        "  \n",
        "\n",
        "    \n",
        "\n",
        "    # Perform PGD attack\n",
        "    lb = np.ndarray.min(x_train_features.toarray())\n",
        "    ub = np.ndarray.max(x_train_features.toarray())\n",
        "    attack_amount = 100\n",
        "    result, cnt, ad_success_x, ori_dataframe, ori_examples2_y, successful_rate = pgd_attack(clf_lin, tr_set, v_set, Y_val, feature_names, attack_amount, dmax, lb, ub)\n",
        "\n",
        "\n",
        "    # Identify magic words\n",
        "    magic_words, spam, ham = magical_word(X_train, X_val, Y_train, Y_val, result, cnt)\n",
        "    m2_empty = svm_attack(method, clf_lin, spam, magic_words, feature_model, feature_names, scalar, 'NaN')\n",
        "    return magic_words\n",
        "\n",
        "# Example usage\n",
        "method = \"word2vec\"  # or \"TFIDF\"\n",
        "dmax = 0.1\n",
        "magic_word = magic_word_attack(method, dmax)\n",
        "print(\"Magic words:\", magic_word)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "34D9Gts3bKTv"
      },
      "source": [
        "### **Task 2** ###\n",
        "Using the function you write for Task 1, run it for 5 times with dmax being 0.02, 0.04, 0.06, 0.08, and 0.1 respectively and repeat this for each feature extraction method being TF-IDF and modified Word2vec. Record the magic word attack success rate and the number of magic words each time and fill in the table below by changing the \"dmax =\" with the actual success rate:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vkPU7B0Z7cFF",
        "outputId": "29488f65-9b3f-4760-dc4f-cd4444c39052"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 0.02\n",
            "1 0.04\n",
            "2 0.06\n",
            "3 0.08\n",
            "4 0.1\n"
          ]
        }
      ],
      "source": [
        "method = \"word2vec\"  # or \"TFIDF\"\n",
        "dmax = 0.02\n",
        "print(\"word2vec:\")\n",
        "for i in range(5):\n",
        "  magic_word = magic_word_attack(method, dmax)\n",
        "  print(\"dmax:\",dmax, \",Magic words:\", magic_word)\n",
        "  dmax+=0.02\n",
        "method = \"TFIDF\" \n",
        "dmax = 0.02\n",
        "print(\"TFIDF:\")\n",
        "for i in range(5):\n",
        "  magic_word = magic_word_attack(method, dmax)\n",
        "  print(\"dmax:\",dmax, \",Magic words:\", magic_word)\n",
        "  dmax+=0.02\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "JcGletlYgMHF"
      },
      "source": [
        "[連結文字](https://)  / | TF-IDF |/\n",
        "-------------------|------------------|------------------\n",
        "dmax = 0.02| success rate = 0.548051948051948| # magic words = arizona chorus cascadilla squib linguistic pkzip translation pp french theory query native glot euralex linguist ldc academic ipa ammondt grammar sentence risked posting proceeding benjamin workshop phonetic\n",
        "dmax = 0.04| success rate = 0.5246753246753246| # magic words =  arizona chorus cascadilla linguistic pkzip translation pp french theory native euralex linguist ldc academic ipa ammondt grammar sentence risked posting proceeding benjamin workshop phonetic\n",
        "dmax = 0.06| success rate = 0.548051948051948 | # magic words = arizona chorus cascadilla squib linguistic pkzip translation pp french theory query native euralex linguist ldc academic ipa ammondt grammar sentence risked posting proceeding benjamin workshop phonetic\n",
        "dmax = 0.08| success rate = 0.5246753246753246 | # magic words =  arizona chorus cascadilla linguistic pkzip translation pp french theory native euralex linguist ldc academic ipa ammondt grammar sentence risked posting proceeding benjamin workshop phonetic\n",
        "dmax = 0.1| success rate = 0.5116883116883116| # magic words =  arizona chorus cascadilla squib linguistic pkzip translation pp french theory query native euralex linguist ldc academic ipa ammondt grammar sentence risked posting proceeding benjamin workshop phonetic"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "hhv1k1i1F3X_"
      },
      "source": [
        "[連結文字](https://)  / | Word2vec |/\n",
        "-------------------|------------------|------------------\n",
        "dmax = 0.02| success rate = 0.6 | # magic words = np belgium clermont linguistic generative universiti corpus lexical pp query colleague directeur linguist grammar titus elsnet restrictive posting professeur sept constraint programme dissertation pdf isbn thierry\n",
        "dmax = 0.04| success rate = 0.5844155844155844| # magic words = np belgium linguistic generative corpus lexical pp query colleague directeur linguist grammar titus elsnet restrictive posting professeur sept constraint programme dissertation pdf isbn thierry\n",
        "dmax = 0.06| success rate = 0.6 | # magic words = np belgium linguistic generative corpus lexical pp query colleague directeur linguist grammar titus elsnet restrictive posting professeur sept constraint programme dissertation pdf isbn thierry\n",
        "dmax = 0.08| success rate = 0.5922077922077922| # magic words = dissertation colleague generative professeur programme np directeur thierry pp corpus elsnet universiti linguistic belgium grammar query linguist lexical pdf posting restrictive titus clermont constraint isbn\n",
        "dmax = 0.1| success rate = 0.6| # magic words = dissertation colleague generative professeur programme np directeur thierry pp corpus elsnet universiti linguistic belgium grammar query linguist lexical pdf posting restrictive titus clermont constraint isbn sept"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "_gzZc4jRiclT"
      },
      "source": [
        "### **Task 3** ###\n",
        "Draw a line graph with the x axis being dmax and the y axis being the attack success rate for each feature extraction method. You will have two plots in this graph. \\\\\n",
        "Answer the questions below: \\\\\n",
        "\n",
        "1.   Which feature extraction method can generate the highest ever magic word attack success rate in all the results? \n",
        "Ans: Word2vec can generate the highest ever magic word attack success rate.\n",
        "2.   Which feature extraction method do you think is the best to resist such attacks? Please explain your choice using the results. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "8F1_bMUJjgre",
        "outputId": "2646801d-ef36-45c4-e7a6-3a7c7c8f626f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.18.2.min.js\"></script>                <div id=\"01378e2e-2b64-4eb5-97c5-de14998545fe\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"01378e2e-2b64-4eb5-97c5-de14998545fe\")) {                    Plotly.newPlot(                        \"01378e2e-2b64-4eb5-97c5-de14998545fe\",                        [{\"mode\":\"lines+markers\",\"name\":\"TFIDF\",\"x\":[0.02,0.04,0.06,0.08,0.1],\"y\":[0.548,0.525,0.548,0.525,0.512],\"type\":\"scatter\"},{\"mode\":\"lines+markers\",\"name\":\"Word2Vec\",\"x\":[0.02,0.04,0.06,0.08,0.1],\"y\":[0.6,0.584,0.6,0.592,0.6],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"title\":{\"text\":\"Magic Word Attack Success Rate vs dmax\"},\"xaxis\":{\"title\":{\"text\":\"dmax\"}},\"yaxis\":{\"title\":{\"text\":\"Success Rate\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('01378e2e-2b64-4eb5-97c5-de14998545fe');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import plotly.graph_objects as go\n",
        "import pandas as pd\n",
        "\n",
        "# Replace these lists with your actual data\n",
        "dmax_values = [0.02, 0.04, 0.06, 0.08, 0.1]\n",
        "tfidf_success_rates = [0.548, 0.525, 0.548, 0.525, 0.512]\n",
        "word2vec_success_rates = [0.6, 0.584, 0.6, 0.592, 0.6]\n",
        "\n",
        "\n",
        "\n",
        "fig = go.Figure()\n",
        "\n",
        "fig.add_trace(go.Scatter(x=dmax_values, y=tfidf_success_rates,\n",
        "                         mode='lines+markers',\n",
        "                         name='TFIDF'))\n",
        "fig.add_trace(go.Scatter(x=dmax_values, y=word2vec_success_rates,\n",
        "                         mode='lines+markers',\n",
        "                         name='Word2Vec'))\n",
        "\n",
        "fig.update_layout(title='Magic Word Attack Success Rate vs dmax',\n",
        "                  xaxis_title='dmax',\n",
        "                  yaxis_title='Success Rate')\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "jOIYXQ2Vjk6Y"
      },
      "source": [
        "Your answers to the two questions:"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "IpuBzQoSkQKM"
      },
      "source": [
        "### **Task 4** ###\n",
        "Please complete the following (in a black-box attack scenario):\n",
        "1. Select a set of maigc words with the highest success rate in task 2\n",
        "2. Train KNN classifiers with the same training dataset provided and the two feature extraction methods you have used to obtain the set of magic word you selected. Here you build two spam filters using a different algorithm. Please show the false negative rates on the testing dataset. \n",
        "3. Pick 100 spam emails and add the magic words to them. Feed them to the two KNN classifiers. Calculate the false negative rates. Can you tell whether the attacks are successful? Ans: Both of the attack success since fn rate of KNN classifiers is higher after the attack happened"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qHfG98jvyj8W",
        "outputId": "b3bacbe2-a739-4b26-af0e-1feb119e0a73"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "crossing boundary interdisciplinary approach latin america th june nd july paper international conference aim explore contemporary cultural debate taking place latin america draw various strand debate multidisciplinary forum paper consider various issue modernization hybridity transculturation apply various field study paper welcome following field cultural study literature particularly looking trend contemporary narrative including neoavantgarde popular fiction drama study cinema gender study popular culture comparative literature anthropology ethnography sociology linguistics economics politics law symposium proposed far include exile latin american experience indigenismo negrismo u s latin america paper longer minute abstract word english spanish portuguese sent preferably email conference organiser department language cultural study university limerick ireland st january conference organizer nuala finnegan kate quinn nancy serrano department language cultural study university limerick limerick ireland tel fax email nuala finnegan ul kate quinn ul nancy serrano ul update visit webpage http www ul neylonm conf html mr michele j neylon department language cultural study university limerick limerick ireland tel http www ul neylonm index html\n",
            "spam receiving message member safemail list wish listclick want site submit definitely web site little use unless interested submit web site different search engine directory guaranteed submission major search engine including alta vista aol netfind excite hotbot infoseek lycos magellan northernlight planet search web crawler yahoo netscape snap com save time trouble promote web site using submit today million web site million web page added day today challenging site easily want site click trouble logging url email requesting information regarding submit click\n",
            "university otago new zealand department english lectureship senior lectureship english linguistics application invited linguist broad general competence icular following field sociolinguistics b semantics c pragmatic successful applicant expected teac h firstyear level applied fashion contribute course li nguistics speciality advanced level candidate completed phd teaching experience addition teaching duty expected pursue stimulate supervise research field s expertise current salary range nz pa bar nz lecur er nz pa bar nz senior lecturer nz position available september hoped succe ssful applicant assume duty close possible date information method application available registrar university otago po box dunedin new zealand fax quote reference number closing date application june lectureship senior lectureship english rhetoric composition application invited lectureship senior lectureship field r hetoric composition related field applicant expertise second field relating toenglish language literature english literary stylistics history language american literature successful applicant expected teach firstyear level ap plied fashion contribute course speciality applied fashion advanced level candidate completed phd teaching experience addition teaching duty expected pursue stimulate supervise r esearch field s expertise current salary range nz pa bar nz lectu rers nz pa bar nz nz position available september hoped succe ssful applicant assume duty close possible date application quoting reference number close june registrar university otago po box dunedin new zealand equal opportunity employment university policy\n",
            "claimed incorrectly german sentence nominative accusative case syncretism like unambiguous clauseinitial noun phrase construed subject die tochter hat die mutter gek usst thenom acc daughter thenom acc mother kissed allegedly svo daughter kissed mother allegedly ov mother kissed daughter fact ambiguous svo interpretation doe preferred ov interpretation outof theblue context steer discussion example german verbsecond language parsing literature thanks beatrice santorini bsantorini nwu edu\n",
            "want respond post particularly caught attention\n",
            "enjoying discussion nice end chaos multiple standard single recommended lsa ipa cooperatively designed think impossible achieve concensus old americanist v ipa debate issue break away continue use system developed time standard linguistic work particular language family disparity linguistic writing official practical writing system accepted language community linguistically adequate preferred linguist speaker better access information recorded published linguist suppose consideration need attempting come consensus encourage introductory text linguistics use particular student forced develop knowledge multiple writing system soon start reading article textbook come enjoy diversity writing system enjoy diversity language leanne hinton dept linguistics university california berkeley ca email hinton violet berkeley edu fax phone\n",
            "False negative rate for TFIDF before attack: 0.03125\n",
            "False negative rate for Word2Vec before attack: 0.5625\n",
            "[1 0 0 1 1 1 0 0 0 0 1 1 1 0 1 0 0 1 1 0 0 0 1 0 1 0 1 0 0 1 0 0 1 0 0 1 0\n",
            " 0 0 1 0 1 0 1 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
            " 1 0 0 0 1 0 1 1 1 0 0 0 1 0 1 0 0 0 0 0 0 1 0 1 1 0] [1 0 1 1 1 1 0 1 1 1 1 0 1 0 1 1 0 1 1 1 1 0 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 0 1 1 1 0 1 1 1 1 0 0 0 1 1 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 0 0 1\n",
            " 1 0 1 0 1 1 1 1 1 0 1 1 1 1 1 0 0 1 0 1 1 1 0 1 1 0]\n",
            "[[ 0  0]\n",
            " [26 74]] [[ 0  0]\n",
            " [67 33]]\n",
            "False negative rate for TFIDF after attack: 0.26\n",
            "False negative rate for Word2Vec after attack: 0.67\n",
            "The attack is successful for the TFIDF-based classifier.\n",
            "The attack is successful for the Word2Vec-based classifier.\n"
          ]
        }
      ],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import pandas as pd\n",
        "# Load your dataset, split it into training, validation, and test sets\n",
        "# x_train, x_test, x_val, y_train, y_test, y_val = load_and_split_data()\n",
        "X_train, X_val, X_test, y_train, y_val, y_test = data_extraction()\n",
        "# Perform feature extraction using the provided code\n",
        "x_train_tfidf, x_test_tfidf, x_val_tfidf, tfidf_feature_names, tfidf_model, _ = feature_extraction(x_train, x_test, x_val, method='TFIDF')\n",
        "x_train_w2v, x_test_w2v, x_val_w2v, w2v_feature_names, w2v_model, scaler = feature_extraction(x_train, x_test, x_val, method='word2vec')\n",
        "\n",
        "# Train KNN classifiers\n",
        "knn_tfidf = KNeighborsClassifier()\n",
        "knn_tfidf.fit(x_train_tfidf, y_train)\n",
        "\n",
        "knn_w2v = KNeighborsClassifier()\n",
        "knn_w2v.fit(x_train_w2v, y_train)\n",
        "\n",
        "# Test the classifiers\n",
        "y_pred_tfidf = knn_tfidf.predict(x_test_tfidf)\n",
        "y_pred_w2v = knn_w2v.predict(x_test_w2v)\n",
        "\n",
        "# Calculate false negative rates before the attack\n",
        "cm_tfidf = confusion_matrix(y_test, y_pred_tfidf)\n",
        "cm_w2v = confusion_matrix(y_test, y_pred_w2v)\n",
        "\n",
        "fn_rate_tfidf_before = cm_tfidf[1][0] / (cm_tfidf[1][0] + cm_tfidf[1][1])\n",
        "fn_rate_w2v_before = cm_w2v[1][0] / (cm_w2v[1][0] + cm_w2v[1][1])\n",
        "\n",
        "print(\"False negative rate for TFIDF before attack:\", fn_rate_tfidf_before)\n",
        "print(\"False negative rate for Word2Vec before attack:\", fn_rate_w2v_before)\n",
        "\n",
        "# Add magic words to 100 spam emails\n",
        "magic_words = [\"np\", \"belgium\", \"clermont\", \"linguistic\", \"generative\", \"universiti\", \"corpus\", \"lexical\", \"pp\", \"query\", \"colleague\", \"directeur\", \"linguist\", \"grammar\", \"titus\", \"elsnet\", \"restrictive\", \"posting\", \"professeur\", \"sept\", \"constraint\", \"programme\", \"dissertation\", \"pdf\", \"isbn\", \"thierry\"]  # Replace with the selected magic words\n",
        "df = pd.read_csv('messages.csv')\n",
        "spam_emails = df[df['label'] == 1]\n",
        "\n",
        "# Randomly pick 100 spam emails\n",
        "selected_spam_emails = spam_emails.sample(n=100, random_state=42)\n",
        "\n",
        "# Reset index\n",
        "selected_spam_emails.reset_index(drop=True, inplace=True)\n",
        "spam_emails_with_magic_words = [email + \" \" + \" \".join(magic_words) for email in selected_spam_emails.message]\n",
        "spam_emails_with_magic_words_series = pd.Series(spam_emails_with_magic_words)\n",
        "# Perform feature extraction on the modified spam emails\n",
        "#print(spam_emails_with_magic_words, spam_emails_with_magic_words_series)\n",
        "x_spam_tfidf = single_transform(spam_emails_with_magic_words_series, 'TFIDF', tfidf_model, tfidf_feature_names, _, _)\n",
        "\n",
        "x_spam_w2v = [single_transform(pd.Series([email]), 'word2vec', w2v_model, w2v_feature_names, scaler, _) for email in spam_emails_with_magic_words_series]\n",
        "#print(x_spam_tfidf)\n",
        "x_spam_w2v = [sparse_matrix.toarray() for sparse_matrix in x_spam_w2v]\n",
        "#print(len(x_spam_w2v[0][0]), len(x_spam_w2v[1][0]))\n",
        "x_spam_w2v = np.vstack(x_spam_w2v)\n",
        "\n",
        "\n",
        "# Test the classifiers on the modified spam emails\n",
        "y_pred_tfidf_attack = knn_tfidf.predict(x_spam_tfidf)\n",
        "y_pred_w2v_attack = knn_w2v.predict(x_spam_w2v)\n",
        "print(y_pred_w2v_attack,y_pred_tfidf_attack)\n",
        "# Calculate false negative rates after the attack\n",
        "cm_tfidf_attack = confusion_matrix([1] * 100, y_pred_tfidf_attack)\n",
        "cm_w2v_attack = confusion_matrix([1] * 100, y_pred_w2v_attack)\n",
        "print(cm_tfidf_attack,cm_w2v_attack)\n",
        "fn_rate_tfidf_attack = cm_tfidf_attack[1][0] / (cm_tfidf_attack[1][0] + cm_tfidf_attack[1][1])\n",
        "fn_rate_w2v_attack = cm_w2v_attack[1][0] / (cm_w2v_attack[1][0] + cm_w2v_attack[1][1])\n",
        "\n",
        "print(\"False negative rate for TFIDF after attack:\", fn_rate_tfidf_attack)\n",
        "print(\"False negative rate for Word2Vec after attack:\", fn_rate_w2v_attack)\n",
        "\n",
        "if fn_rate_tfidf_attack > fn_rate_tfidf_before:\n",
        "    print(\"The attack is successful for the TFIDF-based classifier.\")\n",
        "else:\n",
        "    print(\"The attack is not successful for the TFIDF-based classifier.\")\n",
        "\n",
        "if fn_rate_w2v_attack > fn_rate_w2v_before:\n",
        "    print(\"The attack is successful for the Word2Vec-based classifier.\")\n",
        "else:\n",
        "    print(\"The attack is not successful for the Word2Vec-based classifier.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
